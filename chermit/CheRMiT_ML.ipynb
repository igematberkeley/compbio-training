{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pattern Matching\n",
        "### (Are these allowed to be published? Please let me know.)\n",
        "\n",
        "https://drive.google.com/file/d/1_vFzsHsZ78Cg7Hy2-V6Fk-hpXifeqsgx/view\n",
        "\n",
        "https://drive.google.com/file/d/1upNVxYjCRbw5eLbRvkOE2uEHWEj2PrBX/view\n",
        "\n",
        "These were previously used methods to classify chemical reactions that used pattern matching, and they are also what inspired the CheRMiT project to begin with back in 2020. You need not read through these in detail, but give them a skim so you can build some context about our project's history!\n",
        "\n",
        "Essentially, they are using patterns in the sentence structures to predict whether the sentence contains a reaction or not. While this is a good start, it's not comprehensive enough to generalize over all scientific literature. Different papers will have different types of sentences, and therefore, better patterns must be used for this type of method to work. That's why we're using ML for our project.\n"
      ],
      "metadata": {
        "id": "6Pcyi2oE3ysR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Snorkel\n",
        "\n",
        "Paper using Snorkel to extract chemical reactions data from scientific literature (what CheRMiT does):\n",
        "\n",
        "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-018-0723-6\n",
        "\n",
        "Snorkel's website:\n",
        "\n",
        "https://www.snorkel.org/\n",
        "\n",
        "We are using Snorkel to help create training data for our machine learning models. Snorkel is a library that allows users to create labeling functions. Each labeling function assigns a label (True, False, or Abstain) to a sentence based on a user-coded heuristic. All of the labeling functions are applied simultaneously to the unlabeled sentences and their results are aggregated to give the sentence a final label. \n",
        "\n",
        "Snorkel is important because machine learning models need accurate labeled data to perform well. A machine learning model is only as good as its data. Please check out the resources above for more context around Snorkel! Once you have a good understanding, continue with the assignment below.\n",
        "\n",
        "-----------"
      ],
      "metadata": {
        "id": "q3PjI5sk41Tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, please write a Snorkel labeling function that classifies a given sentence as **True** (contains a reaction). You can use any aspects of the sentence, such as the words, the sentence structure, or the position of words. Get creative!\n",
        "\n",
        "The rest of the code below will allow you to see your function's accuracy."
      ],
      "metadata": {
        "id": "wUhWkV_FbOur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snorkel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QeHBYbuHv4z",
        "outputId": "f1a164c8-2358-4c29-f91a-352d3fc3d47b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.9)\n",
            "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.0.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.6.3)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.12.1+cu113)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.21.6)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.10.0)\n",
            "Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->snorkel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->snorkel) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->snorkel) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->snorkel) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->snorkel) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (1.48.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (1.35.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->snorkel) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from snorkel.labeling import labeling_function\n",
        "import regex as re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ABSTAIN = -1\n",
        "\n",
        "# Example labeling functions below.\n",
        "\n",
        "# includes_reaction_words\n",
        "# If the sentence contains reactions words, we label True\n",
        "reaction_terms_specific = \"conver|yield|synthesiz|synthesis|oxid|reduc|phosphorylat\" + \\\n",
        "                 \"|metaboliz|metabolis|generat|hydroly\" + \\\n",
        "                 \"|methylat|brominat|aminat|dehydrat|condensat|degradat|decompos|carboxylat\"\n",
        "@labeling_function()\n",
        "def includes_reaction_words2(x):\n",
        "    structure = \"(\" + reaction_terms_specific + \")\"\n",
        "    if (re.search(structure, x[0])):\n",
        "        return True\n",
        "    return ABSTAIN\n",
        "\n",
        "# puts chemicals separated by or for regex structures\n",
        "def helper_sep_chems_with_or(chemicals):\n",
        "    final = \"\"\n",
        "    for chem in chemicals:\n",
        "        if (final == \"\"):\n",
        "            final += re.escape(chem)\n",
        "        else:\n",
        "            final += \"|\" + re.escape(chem)\n",
        "    return final\n",
        "\n",
        "# Phil's version: structure_jtsui_pattern_1\n",
        "# If part of the sentence contains the specific structure\n",
        "# [trigger1] <0,3> chemical [transition] <0,3> chemical, we label True\n",
        "\n",
        "TRANS = \"from|to|into|by|are|yield\"\n",
        "TRIG1 = \"phosphoryl|condens|hydrolys|metabol|reduc|conver|produc|form|oxid|transform|bioconver|synthes|react|interconver\"\n",
        "TRANS_p = \"(\" + TRANS + \")\"\n",
        "TRIG1_p = \"(\" + TRIG1 + \")\"\n",
        "\n",
        "@labeling_function()\n",
        "def structure_jtsui_pattern_1(x):\n",
        "    chemicals = helper_sep_chems_with_or(x[1])\n",
        "    chemicals_p = \"(\" + chemicals + \")\"\n",
        "\n",
        "    structure = r\"\\b\" + r\"{}\".format(TRIG1_p) + r\"\\w*(\\s\\w*){0,3}\\s\" + r\"{}\".format(chemicals_p) + r\"\\s\" + r\"{}\".format(TRANS_p) + r\"(\\s\\w*){0,3}\\s\" + r\"{}\".format(chemicals_p)\n",
        "\n",
        "    if (re.search(structure, x[0])):\n",
        "        return True\n",
        "    return ABSTAIN"
      ],
      "metadata": {
        "id": "xXgPrY-3bLRb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Code your labeling function here and add it to your_lf\n",
        "\n",
        "@labeling_function()\n",
        "def your_lf_here(x):\n",
        "    return False\n",
        "your_lf = [your_lf_here]"
      ],
      "metadata": {
        "id": "r7mETRkiG2jw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ground truth values to test your LF\n",
        "df_test = pd.read_csv(\"df_test.csv\", index_col=[0])\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "bSqMx96FG5Ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "36250e76-ab06-4c36-a12e-f25f6261640b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  indomethacin inhibited both hcox-1 and hcox-2,...   \n",
              "1  both ns-398 and dup-697 exhibited time-depende...   \n",
              "2  to understand the signal transduction pathway ...   \n",
              "3  although dopamine does not readily cross the b...   \n",
              "4  because gastric aadc and comt degrade levodopa...   \n",
              "\n",
              "                                  chemicals  truth substrates products  \\\n",
              "0     ['ns-398', 'indomethacin', 'dup-697']      0        NaN      NaN   \n",
              "1     ['ns-398', 'dup-697', 'indomethacin']      0        NaN      NaN   \n",
              "2               ['ceramide', 'c2-ceramide']      0        NaN      NaN   \n",
              "3                  ['dopamine', 'levodopa']      0        NaN      NaN   \n",
              "4  ['carbidopa', 'benserazide', 'levodopa']      0   levodopa      NaN   \n",
              "\n",
              "                                                text  \n",
              "0  ['indomethacin inhibited both hcox-1 and hcox-...  \n",
              "1  ['both ns-398 and dup-697 exhibited time-depen...  \n",
              "2  ['to understand the signal transduction pathwa...  \n",
              "3  ['although dopamine does not readily cross the...  \n",
              "4  ['because gastric aadc and comt degrade levodo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be9a8ebe-88eb-4fd8-9da3-ab0009351a7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>chemicals</th>\n",
              "      <th>truth</th>\n",
              "      <th>substrates</th>\n",
              "      <th>products</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>indomethacin inhibited both hcox-1 and hcox-2,...</td>\n",
              "      <td>['ns-398', 'indomethacin', 'dup-697']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['indomethacin inhibited both hcox-1 and hcox-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>both ns-398 and dup-697 exhibited time-depende...</td>\n",
              "      <td>['ns-398', 'dup-697', 'indomethacin']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['both ns-398 and dup-697 exhibited time-depen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>to understand the signal transduction pathway ...</td>\n",
              "      <td>['ceramide', 'c2-ceramide']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['to understand the signal transduction pathwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>although dopamine does not readily cross the b...</td>\n",
              "      <td>['dopamine', 'levodopa']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['although dopamine does not readily cross the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>because gastric aadc and comt degrade levodopa...</td>\n",
              "      <td>['carbidopa', 'benserazide', 'levodopa']</td>\n",
              "      <td>0</td>\n",
              "      <td>levodopa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['because gastric aadc and comt degrade levodo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be9a8ebe-88eb-4fd8-9da3-ab0009351a7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be9a8ebe-88eb-4fd8-9da3-ab0009351a7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be9a8ebe-88eb-4fd8-9da3-ab0009351a7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from snorkel.labeling import PandasLFApplier\n",
        "\n",
        "applier_test = PandasLFApplier(lfs=your_lf)\n",
        "L_test = applier_test.apply(df=df_test)\n",
        "\n",
        "from snorkel.labeling.model import MajorityLabelVoter\n",
        "\n",
        "majority_model = MajorityLabelVoter()\n",
        "df_test[\"label_voter\"] = majority_model.predict(L=L_test)\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Zdsm41dqKHr5",
        "outputId": "9c9d2ed2-626a-4860-da06-b742d00d35d0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 405/405 [00:00<00:00, 68322.13it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  indomethacin inhibited both hcox-1 and hcox-2,...   \n",
              "1  both ns-398 and dup-697 exhibited time-depende...   \n",
              "2  to understand the signal transduction pathway ...   \n",
              "3  although dopamine does not readily cross the b...   \n",
              "4  because gastric aadc and comt degrade levodopa...   \n",
              "\n",
              "                                  chemicals  truth substrates products  \\\n",
              "0     ['ns-398', 'indomethacin', 'dup-697']      0        NaN      NaN   \n",
              "1     ['ns-398', 'dup-697', 'indomethacin']      0        NaN      NaN   \n",
              "2               ['ceramide', 'c2-ceramide']      0        NaN      NaN   \n",
              "3                  ['dopamine', 'levodopa']      0        NaN      NaN   \n",
              "4  ['carbidopa', 'benserazide', 'levodopa']      0   levodopa      NaN   \n",
              "\n",
              "                                                text  label_voter  \n",
              "0  ['indomethacin inhibited both hcox-1 and hcox-...            0  \n",
              "1  ['both ns-398 and dup-697 exhibited time-depen...            0  \n",
              "2  ['to understand the signal transduction pathwa...            0  \n",
              "3  ['although dopamine does not readily cross the...            0  \n",
              "4  ['because gastric aadc and comt degrade levodo...            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d03c698c-3846-443c-b84b-86465c6caf09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>chemicals</th>\n",
              "      <th>truth</th>\n",
              "      <th>substrates</th>\n",
              "      <th>products</th>\n",
              "      <th>text</th>\n",
              "      <th>label_voter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>indomethacin inhibited both hcox-1 and hcox-2,...</td>\n",
              "      <td>['ns-398', 'indomethacin', 'dup-697']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['indomethacin inhibited both hcox-1 and hcox-...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>both ns-398 and dup-697 exhibited time-depende...</td>\n",
              "      <td>['ns-398', 'dup-697', 'indomethacin']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['both ns-398 and dup-697 exhibited time-depen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>to understand the signal transduction pathway ...</td>\n",
              "      <td>['ceramide', 'c2-ceramide']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['to understand the signal transduction pathwa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>although dopamine does not readily cross the b...</td>\n",
              "      <td>['dopamine', 'levodopa']</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['although dopamine does not readily cross the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>because gastric aadc and comt degrade levodopa...</td>\n",
              "      <td>['carbidopa', 'benserazide', 'levodopa']</td>\n",
              "      <td>0</td>\n",
              "      <td>levodopa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['because gastric aadc and comt degrade levodo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d03c698c-3846-443c-b84b-86465c6caf09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d03c698c-3846-443c-b84b-86465c6caf09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d03c698c-3846-443c-b84b-86465c6caf09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of positive sentences in our ground truth data\n",
        "num_correct = len(df_test[(df_test[\"truth\"] == 1) & (df_test[\"label_voter\"] == 1)])\n",
        "\n",
        "num_positive = len(df_test[df_test[\"truth\"] == 1])\n",
        "\n",
        "accuracy = num_correct / num_positive\n",
        "\n",
        "print(\"Number of sentences your LF labeled correctly: \" + str(num_correct))\n",
        "print(\"Number of true sentences: \" + str(num_positive))\n",
        "print(\"Your Lf's accuracy: \" + str(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29AomK00Lm0z",
        "outputId": "707149d9-bd54-435b-e2ae-f86f0c82e4c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences your LF labeled correctly: 0\n",
            "Number of true sentences: 45\n",
            "Your Lf's accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning\n",
        "\n",
        "Machine learning is the second integral part of our project. When it comes to automatically classifying reactions, there is only so much that can be achieved using chemical logic (RDKit) and pattern matching (Snorkel).\n",
        "\n",
        "For example, the Snorkel pipeline that we're currently using has lots of limitations. It only works on single sentences with explicit substrate and product, it only uses a small number of labeling functions to classify the sentences, it doesn't account for sentences with enzymatic reactions or multiple reactions, and it would probably have trouble with new types of reactions.\n",
        "\n",
        "However, with machine learning, we can solve all of these shortcomings.\n",
        "\n",
        "-------"
      ],
      "metadata": {
        "id": "GEQVSiVEUOYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overarching goal of machine learning is to **find patterns in data and use them to make predictions**. That is, given a set of labeled data, predict a new, unlabeled data point's label. The quality of an ML model is determined by how well it can predict the labels of data points it hasn't seen before.\n",
        "\n",
        "Often, the patterns that ML models are learning to make these predictions aren't obvious to humans. These patterns must be learned by **optimization algorithms**, which essentially find maxima or minima on functions relevant to the data. \n",
        "\n",
        "The most common optimization algorithm used is **gradient descent**, which calculates the gradient of a function, and then updates the model by traveling slightly in the direction of the gradient. This works becuse the gradient will be the direction of steepest ascent/descent, so traveling down the gradient will bring you closer to the extrema.\n",
        "\n",
        "Why would you want to find the extrema of a function? An example function that an optimization algorithm might be used on is a **cost function**. Cost functions are usually an aggregate of **loss functions**. And most loss functions consist of comparing the output of the ML model (inpute label * weights) to the ground truth label. So minimizing a cost function essentially minimizes your error.\n",
        "\n"
      ],
      "metadata": {
        "id": "_ayH6t83XQwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://people.eecs.berkeley.edu/~jrs/189/lec/17.pdf\n",
        "\n",
        "Read the CS 189 lecture notes on neural networks and answer the following questions."
      ],
      "metadata": {
        "id": "5LuYQswrHw8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the function being optimized for NNs?"
      ],
      "metadata": {
        "id": "6oG9wfrIH2Iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is backpropagation? (You'll see this again in the PyTorch section)"
      ],
      "metadata": {
        "id": "pJ5cT0ZLH7vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "\n",
        "PyTorch is a common library to use for general machine learning. Most of the ML tools we'll use in CheRMiT will build off of PyTorch or a similar library (e.g. TensorFlow or Keras). We want you to have a general understanding of how PyTorch works, as well as how neural networks in general work.\n",
        "\n",
        "Please go through this PyTorch tutorial if you don't know the basics of PyTorch. Try out the Colab notebooks! You'll get to train a simple neural network.\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
      ],
      "metadata": {
        "id": "00iKNjVeYawU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've gone through the PyTorch tutorial, answer the following question:\n",
        "\n",
        "How would you code a training loop in torch? Write your loop code below."
      ],
      "metadata": {
        "id": "PRrKSzbyl5nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# TODO: Write your PyTorch training loop code."
      ],
      "metadata": {
        "id": "qU1qw5HXmA6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace\n",
        "\n",
        "NLP is the subset of ML that we will be using for CheRMiT. It is concerned with making predictions about language. The most prominent library for using and understanding NLP is HuggingFace.\n",
        "\n",
        "To get a sense of what NLP models are capable of, we'd like you to check out this Colab notebook.\n",
        "\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb\n",
        "\n",
        "The associated tutorial for this notebook is on HuggingFace's webpage: https://huggingface.co/course/chapter1/3?fw=pt\n",
        "\n",
        "These models are super cool! We hope you think so too. To show you've checked out these resources, code a simple pipeline function below and run it on a sentence of your choice."
      ],
      "metadata": {
        "id": "8hfL-54h0cCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "\n",
        "#TODO: Call a pipeline function on a sentene of your choice."
      ],
      "metadata": {
        "id": "0bBt1rejbJhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChemRxnBert\n",
        "\n",
        "While the general use NLP models are cool and give us a sense of what types of tasks are possible to achieve with language, we need models trained on more specific data for our use case. Specifically, we need models that are trained on chemical entities and sientific literature. \n",
        "\n",
        "\n",
        "https://pubs.acs.org/doi/pdf/10.1021/acs.jcim.1c00284\n",
        "\n",
        "This paper was released last year. It describes a deep learning model that extracts chemical reaction data from scientific literature. Please read through the whole thing closely and annotate it, since we'll be referencing and building off of it heavily this year. In a future team meeting, we will all discuss our annotations.\n",
        "\n",
        "https://github.com/jiangfeng1124/ChemRxnExtractor\n",
        "\n",
        "Please use the README on their Github to install their package. Then, play around with it! Download the trained models and use them to predict unlabeled sentences that you've found. (There are some in the Snorkel df_test, if you need.) \n",
        "\n",
        "You can find the correct data format for using their predict function on the inputs.txt file, which is located on their pipeline branch.\n",
        "\n",
        "https://github.com/asibanez/chemie-turk\n",
        "\n",
        "You can also use this package to annotate sentences in their specific format if you need to. \n",
        "\n",
        "------\n",
        "\n",
        "I'm thinking that this year, we can use their models along with our additional tools to make an improved pipeline! They seemed to have the most problems with differentiating between substrates and catalysts, but our cheminformatics suite should be able to help with that."
      ],
      "metadata": {
        "id": "3LvSFVtvTKGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jiangfeng1124/ChemRxnExtractor\n",
        "%cd ChemRxnExtractor\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbied5w3x0yO",
        "outputId": "77340bbf-dd12-4ef4-8042-8d932adedf60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChemRxnExtractor'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 249 (delta 42), reused 39 (delta 39), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (249/249), 1.02 MiB | 13.62 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "/content/ChemRxnExtractor/ChemRxnExtractor\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.5.0\n",
            "  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 752.0 MB 9.5 kB/s \n",
            "\u001b[?25hCollecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 58.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 5)) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r requirements.txt (line 2)) (7.1.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=6192b049614f8e015cb20cc61e105898e669efdbe995bddc48a570589f5ea262\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, torch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.22.1\n",
            "    Uninstalling transformers-4.22.1:\n",
            "      Successfully uninstalled transformers-4.22.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.5.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.5.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.5.0 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.5.0 which is incompatible.\u001b[0m\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 torch-1.5.0 transformers-3.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/ChemRxnExtractor/ChemRxnExtractor\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from chemrxnextractor==1.1.0) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.36.0 in /usr/local/lib/python3.7/dist-packages (from chemrxnextractor==1.1.0) (4.64.1)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from chemrxnextractor==1.1.0) (3.0.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from chemrxnextractor==1.1.0) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chemrxnextractor==1.1.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->chemrxnextractor==1.1.0) (0.16.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (0.0.53)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (21.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (0.1.97)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (3.8.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (0.8.1rc1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->chemrxnextractor==1.1.0) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.0.2->chemrxnextractor==1.1.0) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->chemrxnextractor==1.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->chemrxnextractor==1.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->chemrxnextractor==1.1.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->chemrxnextractor==1.1.0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->chemrxnextractor==1.1.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->chemrxnextractor==1.1.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->chemrxnextractor==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->chemrxnextractor==1.1.0) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->chemrxnextractor==1.1.0) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->chemrxnextractor==1.1.0) (3.1.0)\n",
            "Installing collected packages: chemrxnextractor\n",
            "  Attempting uninstall: chemrxnextractor\n",
            "    Found existing installation: chemrxnextractor 1.1.0\n",
            "    Can't uninstall 'chemrxnextractor'. No files were found to uninstall.\n",
            "  Running setup.py develop for chemrxnextractor\n",
            "Successfully installed chemrxnextractor-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chemrxnextractor import RxnExtractor"
      ],
      "metadata": {
        "id": "VBedqTDJySQD"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}